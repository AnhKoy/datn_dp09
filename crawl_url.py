import sys
import io

from sqlalchemy import true
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.wait import WebDriverWait
import selenium.webdriver.support.expected_conditions as EC
import undetected_chromedriver as uc
import time
import numpy as np
import pandas as pd
from urllib.parse import urlparse, parse_qs, unquote

#=============================================================================================================================

# Cáº¥u hÃ¬nh Chrome
options = uc.ChromeOptions()
options.add_argument("--headless")  # KHÃ”NG nÃªn báº­t headless khi test, hÃ£y Ä‘á»ƒ má»Ÿ
options.add_argument("--start-maximized")
options.add_argument("--disable-infobars")
options.add_argument("--window-size=1920,1080")
options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36")

options.add_argument("--disable-extensions")
options.add_argument("--disable-gpu")
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")
options.add_argument("--disable-blink-features=AutomationControlled")
options.add_argument("--ignore-certificate-errors")
options.add_argument("--ignore-ssl-errors")

# sá»­a Ä‘Ãºng Ä‘Æ°á»ng dáº«n file chromedriver
driver = uc.Chrome(driver_executable_path=r"E:\DATA\DuAn\BatDongSan\drivers\chromedriver-win64\chromedriver.exe",
                   options=options,
                   headless=true)

def get_hrefs_from_page(url):
    driver.get(url)
    print("Page title:", driver.title)
    print("HTML length:", len(driver.page_source))
    
    try:
        # Äá»£i tháº» <a> chá»©a class vÃ  data-product-id xuáº¥t hiá»‡n
        WebDriverWait(driver, 30).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, "a.js__product-link-for-product-id[data-product-id]"))
        )
        elements = driver.find_elements(By.CSS_SELECTOR, "a.js__product-link-for-product-id[data-product-id]")

        hrefs = []
        for el in elements:
            href = el.get_attribute("href")
            if href:
                # GhÃ©p domain náº¿u lÃ  Ä‘Æ°á»ng dáº«n tÆ°Æ¡ng Ä‘á»‘i
                if not href.startswith("http"):
                    href = "https://batdongsan.com.vn" + href
                hrefs.append(href)

        return hrefs

    except Exception as e:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y sáº£n pháº©m trÃªn trang: {url} - Lá»—i: {e}")
        return []

# Báº¯t Ä‘áº§u crawl tá»«ng trang vÃ  lÆ°u tá»«ng trang ngay vÃ o file
base_url = "https://batdongsan.com.vn/nha-dat-ban-ha-noi"
page = 1
total_count = 0

output_path = r"E:\DATA\DuAn\BatDongSan\n8n\hrefs.txt"

with open(output_path, "w", encoding="utf-8") as file:
    while page <= 30:
        url = f"{base_url}/p{page}" if page > 1 else base_url
        print(f"\nğŸ“„ Äang xá»­ lÃ½ trang {page}: {url}")

        hrefs = get_hrefs_from_page(url)
        if not hrefs:
            print("â›” KhÃ´ng tÃ¬m tháº¥y href nÃ o. Káº¿t thÃºc.")
            break

        for href in hrefs:
            file.write(href + "\n")
        total_count += len(hrefs)

        print(f"âœ… LÆ°u {len(hrefs)} href tá»« trang {page} vÃ o file.")

        # Kiá»ƒm tra cÃ²n nÃºt trang khÃ´ng (tá»©c lÃ  cÃ²n next page khÃ´ng)
        next_page = driver.find_elements(By.CSS_SELECTOR, 'a.re__pagination-icon:not(.re__pagination-icon--no-effect)')
        if not next_page:
            print("âœ… Háº¿t trang.")
            break

        page += 1
        time.sleep(2)

print(f"\nğŸ‰ Tá»•ng cá»™ng Ä‘Ã£ lÆ°u: {total_count} href vÃ o file hrefs.txt")
driver.quit()
